La Recomendación sobre la ética de la inteligencia artificial es el primer instrumento normativo mundial sobre la ética de la inteligencia artificial, aprobado el 23 de noviembre de 2021 durante la 41ª Conferencia General de la UNESCO. El proceso de elaboración del proyecto de texto comenzó en 2020 con la asistencia de un Grupo de Expertos y Expertas Ad Hoc que realizaron amplias consultas inclusivas y multidisciplinares con una extensa gama de partes interesadas. A continuación, hacia finales de 2020 y durante 2021 se realizó un proceso intergubernamental y una negociación del proyecto para finalmente producir una versión definitiva a finales de ese mismo año.[1]​
Aquello que se pretende mediante la Recomendación es traducir los principios éticos de la inteligencia artificial a acciones políticas que garanticen el beneficio popular de los avances que proponen estas tecnologías, desde cumplir los derechos humanos hasta contribuir al desarrollo sostenible. Es, por tanto, un método para enlazar su funcionamiento al servicio humano y a la prevención de riesgos.[2]​

Como explica Audrey Azoulay, Directora General de la UNESCO:“El mundo necesita reglas para que la inteligencia artificial beneficie a la humanidad. La Recomendación sobre la ética de la IA es una respuesta importante. Establece el primer marco normativo mundial, al tiempo que otorga a los Estados la responsabilidad de aplicarlo a su nivel. La UNESCO apoyará a sus 193 Estados Miembros en su aplicación y les pedirá que informen periódicamente sobre sus progresos y prácticas.”Además de valores y principios, la Recomendación contiene acciones políticas en once ámbitos de actuación diferentes: Evaluación de impacto ético, Gobernanza y administración éticas, Política de datos, Desarrollo y cooperación internacional, Medio ambiente y ecosistemas, Género, Cultura, Educación e investigación, Comunicación e información, Economía y trabajo, y Salud y bienestar social.
Los objetivos principales de la Recomendación van dirigidos a ofrecer una serie de bases éticas que concuerden con los derechos humanos, se atengan a una ley de no discriminación y a favor del medio ambiente sobre las que formular las leyes que rijan esta inteligencia artificial. Así mismo, buscan que no sean solo las instituciones oficiales o los Gobiernos, sino que entidades privadas y particulares también se atiendan a dichos principios. Busca abrir una línea de diálogo y de información entre todos aquellos implicados en el mundo de la tecnología relativo a estos avances y poner al alcance de cualquiera —independientemente de los recursos de los que dispongan— los beneficios de la IA. En general, pretende servir como orientación a la hora de determinar el buen uso y comportamiento de la IA.
A continuación, se citan textualmente los objetivos expuestos en el documento oficial de la UNESCO[3]​:
Las personas e instituciones (privadas o oficiales) son libres de usar los sistemas de IA durante todo su ciclo de vida. Estos, pero, y el uso que se hace, no pueden violar los principios de los derechos humanos ni arrebatar la dignidad de las personas, independientemente de sus factores definitorios (raza, religión, sexo etc.). Así mismo, aunque se puede hacer uso de la IA para el cuidado de personas en situación de vulnerabilidad, este modo de empleo no puede sobrepasar los límites de sus libertades fundamentales ni atentar contra su dignidad.
Los sistemas de IA y todos los participantes en su ciclo de vida, deben trabajar y funcionar desde una consciencia medioambiental, intentando participar en la conservación de los ecosistemas. Para ello tendrán que atenerse a las leyes marcadas por territorio y a nivel global, así como procurar reducir su impacto ambiental, especialmente su huella de carbono. 
El uso de un sistema de IA no puede ser denegado a ninguna persona debido a diferencias culturales, étnicas, de raza, de posición económica, de posicionamiento político, de género, de edad, de idioma, de sexualidad o cualquier otro motivo. Se debe promover la diversidad y el respeto mutuo. A su misma vez, se debe trabajar para paliar las diferencias en posibilidad de acceso a infraestructuras, materiales y educación que provoca la brecha económica con países de ingreso mediano bajo, PMA, PDSL y PEID. 
Durante su ciclo de vida, la IA y sus desarrolladores deben advocar por la interconexión, la solidaridad y la convivencia pacífica entre los seres humanos. En ningún momento se debe segregar, cosificar, dividir o enfrentar a personas o grupos, ni tampoco disrumpir contra la coexistencia entre seres humanos, seres vivos y el medio natural. 
Los sistemas de IA no deben utilizarse con fines de calificación social o vigilancia masiva. El método de IA debe ser adecuado y proporcional para alcanzar un fin legítimo determinado; no debe constituir una violación o un abuso de los derechos humanos; y debe ser adecuado al contexto y basarse en fundamentos científicos rigurosos.
Los riesgos de seguridad y protección deben prevenirse y eliminarse a lo largo del ciclo de vida de los sistemas de IA a través del desarrollo de marcos de acceso a los datos que sean sostenibles, respeten la privacidad y fomenten la utilización de datos de calidad en las IA.
Los actores de la IA deben adoptar un efoque inclusivo que promueva la justicia social, salvaguardar la equidad y luchar contra todo tipo de discriminación conforme el derecho institucional. Para ello, deberían reducirse las brechas digitales y de conocimiento, y garantizar el acceso inclusivo al desarrollo de la IA y la participación en él. Además, debería disponerse de un recurso efectivo contra la discriminación y la determinación algorítmica sesgada. 
Los efectos de la IA en el ámbito humano, social, cultural, económico y ambiental deben evaluarse en pleno conocimiento de que el desarrollo de estos tiene repercusiones (beneficiosas o perjudiciales) inmediatas en la sostenibilidad. Se deben establecer, entonces, unas  metas en evolución constante referidas a una serie de dimensiones, como las propuestas en los Objetivos de Desarrollo Sostenible (ODS) de la Naciones Unidas. 
La privacidad debe ser respetada, protegida y promovida durante el ciclo de vida de los sistemas IA mediante marcos de protección de datos y mecanismos de gobernanza adecuados, garantizando un objetivo legítimo y una base jurídica válida para el tratamiento de los datos personales.
La responsabilidad ética y jurídica siempre se debería poder atribuir a personas físicas o entidades jurídicas, ya que la decisión de ceder el control el contextos limitados recae sobre los seres humanos. De esta forma, la supervisión física incluye, además de la supervisión humana individual, la supervisión pública inclusiva.
El grado de transparencia y explicabilidad debe adecuarse al contexto y al efecto con el fin de mantener un equilibrio con los principios de privacidad, seguridad y protección. Las personas deberían saber cuándo una decisión es tomada mediante IA, poder solicitar explicaciones e información al actor de la misma, conocer los motivos por los que una decisión ha sido tomada y poder presentar alegaciones cuando sus derechos y libertades se vean afectados. La transparencia ayuda a las personas a entender el modo de implementación en cada etapa de un sistema de IA en función de su contexto y sensibilidad particular, además de informar sobre los factores presentes en la toma de decisiones. Por otra parte, la explicabilidad consiste en hacer comprensibles los resultados de los sistemas IA y proporcionar información sobre ellos. Este principio está estrechamente ligado con el principio de responsabilidad y rendición de cuentas.
La responsabilidad ética y la obligación de rendir cuentas de las decisiones y acciones tomadas sobre los sistemas de IA deben poderse atribuir, en último término, a los actores de la IA según su función dentro del ciclo de vida del sistemas de IA. Dispositivos técnicos e institucionales deben garantizar la revisión y rastreabilidad de los sistemas de IA con el fin de procurar solucionar cualquier problema relacionado con los derechos humanos y el bienestar del medio ambiente y los ecosistemas. 
Se debe ofrecer una sensibilización del público respecto a la IA a partir de una educación accesible lo más completa posible con la finalidad de que puedan tomar decisiones informadas y no se vean sujetos a injusticias ocasionadas por una desinformación. Este aprendizaje debe hacerse de forma paralela a la comprensión de los derechos humanos y las libertades fundamentales para crear un vínculo en el uso de una (IA) en respeto a las otras (derechos). 
Por lo que concierne el uso de datos, estos se ven sometidos al derecho internacional y la soberanía nacional, hecho que conlleva que los Gobiernos tengan autoridad para regularlos si pasan por su territorio. Las medidas que tomen deberían ser, mayoritariamente, en favor de la privacidad y en respeto a los derechos humanos. Es necesaria la implicación de todos los grupos interesados durante el ciclo de vida de los sistemas de IA (organizaciones gubernamentales, pero también responsables de la educación y órganos de vigilancia de la lucha contra la discriminación) para asegurar la representación de todos los sectores y la capacidad de ayuda de la IA sin sesgo alguno. Además, debe procurarse la inclusión de grupos marginales, indígenas y cualquier otro que pueda surgir y tenga implicación en el uso y/o desarrollo de la IA.
